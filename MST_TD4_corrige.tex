% DST n1

\documentclass[11pt,a4paper]{article}
\usepackage{a4wide}\usepackage{amsmath,amssymb}
\usepackage{dsfont}
\usepackage[latin1]{inputenc} % entree 8 bits iso-latin1
\usepackage[T1]{fontenc}      % encodage 8 bits des fontes utilisees
\usepackage[french]{babel}%typo française
\usepackage{times}
\newcommand{\R}{\mathbb{R}}\newcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}\newcommand{\Q}{\mathbb{Q}}


\def \I{\mathbb{I}}
\def \N{\mathbb{N}}
\def \R{\mathbb{R}}
\def \M{\mathbb{M}}
\def \Z{\mathbb{Z}}
\def \E{\mathbb{E}}
\def \F{\mathbb{F}}
\def \P{\mathbb{P}}
\def \Q{\mathbb{Q}}
\def \D{\mathbb{D}}


\def \Ac{{\cal A}}
\def \Bc{{\cal B}}
\def \Cc{{\cal C}}
\def \Dc{{\cal D}}
\def \Ec{{\cal E}}
\def \Fc{{\cal F}}
\def \Gc{{\cal G}}
\def \Hc{{\cal H}}
\def \Ic{{\cal I}}
\def \Kc{{\cal K}}
\def \Lc{{\cal L}}
\def \Pc{{\cal P}}
\def \Qc{{\cal Q}}
\def \Mc{{\cal M}}
\def \Nc{{\cal N}}
\def \Oc{{\cal O}}
\def \Sc{{\cal S}}
\def \Tc{{\cal T}}
\def \Uc{{\cal U}}
\def \Vc{{\cal V}}
\def \Wc{{\cal W}}
\def \Yc{{\cal Y}}
\def \Zc{{\cal Z}}
\def \Xc{{\cal X}}






\def \PI{\displaystyle\Pi}

\def \Sum{\displaystyle\sum}
\def \Prod{\displaystyle\prod}
\def \Int{\displaystyle\int}
\def \Frac{\displaystyle\frac}
\def \Inf{\displaystyle\inf}
\def \Sup{\displaystyle\sup}
\def \Lim{\displaystyle\lim}
\def \Liminf{\displaystyle\liminf}
\def \Limsup{\displaystyle\limsup}
\def \Max{\displaystyle\max}
\def \Min{\displaystyle\min}




\def \ni{\noindent}

\def \eps{\varepsilon}


\def \ep{\hbox{ }\hfill$\Box$}


\def\Dt#1{\Frac{\partial #1}{\partial t}}
\def\Dx#1{\Frac{\partial #1}{\partial x}}
\def\Ds#1{\Frac{\partial #1}{\partial s}}
\def\Dss#1{\Frac{\partial^2 #1}{\partial s^2}}
\def\Dy#1{\Frac{\partial #1}{\partial y}}
\def\Dyy#1{\Frac{\partial^2 #1}{\partial y^2}}
\def\Dsy#1{\Frac{\partial^2 #1}{\partial s \partial y}}
\def\Dk#1{\Frac{\partial #1}{\partial k}}
\def\Dp#1{\Frac{\partial #1}{\partial p}}
\def\Dkk#1{\Frac{\partial^2 #1}{\partial k^2}}
\def\Dpp#1{\Frac{\partial^2 #1}{\partial p^2}}
\def\Dky#1{\Frac{\partial^2 #1}{\partial k \partial y}}
\def\Dkp#1{\Frac{\partial^2 #1}{\partial k \partial p}}
\def\Dyp#1{\Frac{\partial^2 #1}{\partial y \partial p}}

\def\Dth#1{\Frac{\partial #1}{\partial \theta}}
\def\Dthi#1{\Frac{\partial #1}{\partial \theta_i}}
\def\Dthj#1{\Frac{\partial #1}{\partial \theta_j}}
\def\Dtth#1{\Frac{\partial^2 #1}{\partial \theta^2}}
\def\Dthij#1{\Frac{\partial^2 #1}{\partial \theta_i \partial \theta_j}}

\def\Dth#1{\Frac{\partial #1}{\partial \theta}}
\def\Dtth#1{\Frac{\partial^2 #1}{\partial \theta^2}}

\def\Dlam#1{\Frac{\partial #1}{\partial \lambda}}

\def\reff#1{{\rm(\ref{#1})}}

\def\beqs{\begin{eqnarray*}}
\def\enqs{\end{eqnarray*}}
\def\beq{\begin{eqnarray}}
\def\enq{\end{eqnarray}}






%%%%%\setbeamercovered{dynamic}






\newcounter{exo}
\def\cit{\addtocounter{exo}{-1}\refstepcounter{exo}\label}
\def\exo{\mbox{}\\[0em]\hspace*{0em}\bf Exercice
\addtocounter{exo}{1}\arabic{exo}.\rm\hspace{1ex}}


\begin{document}
\centerline{\sc \'Etude de Cas}  \centerline{~}
\vskip1cm \centerline{{\bf Corrigé TD 4}} \centerline{Février 2011}



\exo Soit $X$ une variable al\'eatoire \`a valeurs dans $\N^*$
d\'efinie comme l'instant de premier succ\`es dans un sch\'ema de
Bernoulli de param\`etre $q \in ]0, 1[$.

\vspace{3mm}

\ni {\bf 1.1. V\'erifier que la loi de $X$ est une loi
g\'eom\'etrique dont on pr\'ecisera le param\`etre.}

\vspace{2mm}

\ni Soit $x\in \N^*$,  $\P_q(X=x) = (1-q)^{x-1} q$. La loi de $X$
est la loi géométrique de paramètre $q$.

\vspace{2mm}


\ni {\bf 1.2. Vérifier qu'il s'agit d'un mod\`ele exponentiel.
Donner une statistique exhaustive.}

\vspace{2mm}

\ni La loi est $p(x,q) = (1-q)^{x-1} q$, on a:
$$ \ln p(x,q) = \ln q - \ln (1-q) + x \ln (1-q)$$
Il s'agit d'un modèle exponentiel. On obtient une statistique
exhaustive suivante (D'après Théorème de Darmois) $T(X) = X$ qui
est la statistique canonique.

\vspace{2mm}

\ni {\bf 1.3. D\'eterminer I(q), l'information de Fisher sur $q$
d'un \'echantillon de taille 1.}

\vspace{2mm}

\ni On a $\frac{\partial}{\partial q}\ln p(x,q) = \frac{1}{q} -
\frac{x-1}{1-q}$ et $\frac{\partial^2}{\partial q^2}\ln p(x,q) = -
\frac{1}{q^2} - \frac{x-1}{(1-q)^2}$. On en déduit
$$I(q) = \frac{1}{q^2} + \frac{E_q[X]-1}{(1-q)^2} =
\frac{1}{q^2(1-q)}$$

\vspace{2mm}

\ni {\bf 1.4. Soit $X_1,...,X_n$ un \'echantillon ind\'ependant de
taille $n$ de m\^eme loi que $X$. D\'eterminer $\hat q_n$,
l'estimateur du maximum de vraisemblance de $q$.}

\vspace{2mm}

\ni La vraisemblance du $n$ échantillon est
$$p_n(x_1,..,x_n, q) = q^n (1-q)^{\sum_{i=1}^n x_i - n}. $$
On regarde les zéros de la dérivée de la log-vraisemblance $l_n =
\ln p_n$, et on vérifie que $\hat q_n = \frac{n}{\Sum_{i=1}^n X_i}
= \frac{1}{\bar X_n}$ est l'EMV de $q$.

\vspace{2mm}

\ni {\bf 1.5. Montrer que l'estimateur du maximum de vraisemblance
est asymptotiquement normal.}

\vspace{2mm}

\ni On peut appliquer le T.C.L. Comme $\hbox{Var}_q(X) =
\frac{1-q}{q^2}$, il vient
$$ \sqrt{n} (\bar X_n - \frac{1}{q}) \mapsto^{loi} \;
\Nc(0,\frac{1-q}{q^2}).$$ Comme la fonction $h(u) = \frac{1}{u}$
est de classe $\mathcal{C}^1$ pour $u>0$, on a la convergence en loi suivante
$$ \sqrt{n} (\frac{1}{\bar X_n} - q) \mapsto^{loi} \;
\Nc(0,\frac{1-q}{q^2} q^4).$$ On obtient ainsi les propriétés
asymptotiques de l'EMV. Ainsi,
$$ \sqrt{n} (\hat q_n - q) \mapsto^{loi} \;
\Nc(0,(1-q)q^2).$$

\vspace{2mm}

\exo On consid\`ere le mod\`ele d'\'echantillonnage $X_1 ...,X_n$
de taille $n$ associ\'e \`a la famille de lois exponentielles $P =
\{\Ec(\lambda), \lambda>0\}$. On veut estimer $\lambda$

\vspace{2mm} Pour les 4 premières questions, voir TD 2 Ex 2.

\ni 2.1. A partir de la m\'ethode des moments, construire un
estimateur convergent $\hat \lambda_n$ de $\lambda$.

\ni 2.2. V\'erifier qu'il s'agit de l'estimateur du maximum de
vraisemblance.

\ni 2.3. D\'eterminer la loi de $\Sigma_{i=1}^n X_i$ . Calculer
$E_{\lambda}[\hat \lambda_n]$. L'estimateur est-il sans biais?

\ni  2.4. D\'eterminer un estimateur $\hat \lambda_n^*$ sans biais
et un estimateur $\hat \lambda_n^o$ qui minimise le risque
quadratique parmi les estimateurs $$ \hat \lambda_n^{(c)} =
\frac{c}{\Sigma_{i=1}^n  X_i}, \: \hbox{où} \: c> 0$$

\vspace{2mm}

\ni {\bf 2.5. Calculer  l'information de Fisher et la borne
Cramer-Rao.}

\vspace{2mm}

\ni Par définition, on a

\beqs \ln L_1(x_1, \lambda) &=& \ln \lambda -  \lambda x_i + \ln
({\bf 1}_{x_1 > 0})\\
\frac{\partial}{\partial \lambda} L_1(x_1, \lambda) &=&
\frac{1}{\lambda} - x_1 \: \hbox{et} \: \frac{\partial^2}{\partial
\lambda^2} L_1(x_1, \lambda) = - \frac{1}{\lambda^2} \enqs On
obtient donc,

$I_1(\lambda) = - E_{\lambda} \left[ \frac{\partial}{\partial
\lambda} L_1(x_1, \lambda) \right]= \frac{1}{\lambda^2}$ et $
\hbox{BCR}(\lambda) = \frac{1}{n I_1(\lambda)} =
\frac{\lambda^2}{n}.$

\vspace{2mm}

\ni {\bf 2.6. Les estimateurs \'etudi\'es font intervenir la
statistique $S_n = \sum_{i=1}^n X_i$. Est-elle exhaustive?}

\vspace{2mm}

\ni On vérifie que le modèle est exponentiel en regardant
$$\ln f(x,\lambda) = \ln \lambda -  \lambda x + \ln ({\bf 1}_{x
> 0})$$ ainsi $f(x,\lambda)$ peut bien s'écrire sous forme
exponentielle. D'après Th. de Darmois, on obtient une statistique
exhaustive: $S_n = S_n(X_1,...,X_n) = \Sum_{i=1}^n X_i$.

\vspace{2mm}

\ni {\bf 2.7. R\'esum\'e : quelles propri\'et\'es $\hat
\lambda_n^*$ a-t-il:} \\
\ni (a) Sans biais: $\hat \lambda_n^*$ a été choisi sans biais.

\ni (b) Efficace: L'estimateur sans biais $\hat \lambda_n^*$ a
comme risque quadratique

$$\hbox{Var}(\hat\lambda_n^*) = R(\hat
\lambda_n^*, \lambda) = \frac{\lambda^2}{(n-1)(n-2)}[(n-1)^2 -
(n-1)(n-2)] = \frac{\lambda^2}{n-2}.$$ Il n'atteint pas la borne
BCR. Il n'est donc pas efficace.

\ni (c) Asymtotiquement normal. Pour répondre à cette question,
nous avons besoin du Théorème de Slutsky qui n'a pas été traité en
cours!

\end{document}
